{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 - The True Power of Qurry\n",
    "\n",
    "In the previous section, we have learned how to use the basic function of Qurry. In this section, we will learn that Qurry provides a more advanced approach, where the true power of Qurry lies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qurry import EntropyMeasure, BackendManager\n",
    "from qiskit import QuantumRegister, ClassicalRegister, QuantumCircuit\n",
    "from pathlib import Path\n",
    "\n",
    "experiment_executor_02 = EntropyMeasure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit.providers.basic_provider import BasicProvider\n",
    "\n",
    "basic_provider = BasicProvider()\n",
    "backend_sim = basic_provider.get_backend(\"basic_simulator\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 - Launching a multiJob\n",
    "\n",
    "Consider a scenario where you have multiple circuits that you want to run on a backend at the same time, you can use `multiOutput` to launch a multiJob.\n",
    "\n",
    "For the example below, we will show how to submit 100 circuits with 100 sets of randomized unitaries and 4096 shots, and mesure the entropy with multiple subsystem divisions at the same time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Loading 10 circuits\n",
    "\n",
    "(Topological Paramagnetic State is already the most complicated case in Qurry, so we will use it as our example. Ususally I prefer some more complicated circuits like a spin chain model with 20+ trotter steps, but it's not necessary for this example.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ┌───┐         \n",
      "q_0: ┤ H ├─■─────■─\n",
      "     ├───┤ │     │ \n",
      "q_1: ┤ H ├─■──■──┼─\n",
      "     ├───┤    │  │ \n",
      "q_2: ┤ H ├─■──■──┼─\n",
      "     ├───┤ │     │ \n",
      "q_3: ┤ H ├─■──■──┼─\n",
      "     ├───┤    │  │ \n",
      "q_4: ┤ H ├─■──■──┼─\n",
      "     ├───┤ │     │ \n",
      "q_5: ┤ H ├─■──■──┼─\n",
      "     ├───┤    │  │ \n",
      "q_6: ┤ H ├─■──■──┼─\n",
      "     ├───┤ │     │ \n",
      "q_7: ┤ H ├─■─────■─\n",
      "     └───┘         \n"
     ]
    }
   ],
   "source": [
    "from qurry.recipe import TopologicalParamagnet\n",
    "sample = TopologicalParamagnet(8, 'period')\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading circuits to `Qurry`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    experiment_executor_02.add(sample)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the name or serial number of the circuit in `Qurry` by `experiment_executor_02.waves.keys()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])\n"
     ]
    }
   ],
   "source": [
    "print(experiment_executor_02.waves.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Preparing configurations\n",
    "\n",
    "To perform randomized measurement, multiple randomized unitary configurations required. We use a list to store all configurations.\n",
    "\n",
    "For randomized measurement, each configuration is in this form of dictionary:\n",
    "\n",
    "```python\n",
    "{\n",
    "    'waves': 'the circuit to measure',\n",
    "    'tags': 'tags for this job',\n",
    "    'times': 100,\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Hashable, Iterable, Union, Optional\n",
    "\n",
    "class randomizedConfig(TypedDict):\n",
    "    wave: Hashable\n",
    "    \"\"\"The name or serial number of circuit in Qurry.\"\"\"\n",
    "    tags: Hashable\n",
    "    \"\"\"You can metion tags to filter experiment.\"\"\"\n",
    "    times: int\n",
    "    \"\"\"Default: 100 in :cls:`RandomizedMeasure`\"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_list = [{\n",
    "    'wave': i,\n",
    "    'tags': ('topParamagnet', int(i/10)),\n",
    "    'times': 100,\n",
    "} for i in range(10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Launching multiJob\n",
    "\n",
    "Attenetion, this example may make your computer go brrrr.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# please un-comment this cell to run it.\n",
    "\n",
    "# hash_id = experiment_executor_02.multiOutput(\n",
    "#     config_list=config_list,\n",
    "#     backend=backend_sim,\n",
    "#     save_location=Path('./'),\n",
    "#     summoner_name='example.multiOutput',\n",
    "#     shots=4096,\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `multiOutput` will return an ID of this multiJob,\n",
    "\n",
    "you can use it to check the status of this multiJob in `experiment_executor_02.multimanagers[(the ID returned)]`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hash_id\n",
    "# The hashID of this multiOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiManagerContainer(num=0, {})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_executor_02.multimanagers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. The automatic export of multiJob\n",
    "\n",
    "After the multiJob is finished, you may notice that there are some new files in your folder, they are the results of your multiJob.\n",
    "\n",
    "Qurry will automatically export the results of multiJob to your folder, and you can use `multiRead` to load them. We will show how to use `multiRead` in later section.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Make multiple analysis with multiple subsystem divisions\n",
    "\n",
    "Attenetion, this example may make your computer go brrrr, too.\n",
    "The post-processing calculation already boosts by multiprocesses, cython and Rust, speeding up the calculation. In early version, such calculation can take all day, even few days to finish.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1],\n",
       " [0, 1, 2, 3],\n",
       " [0, 1, 2, 3, 4, 5],\n",
       " [2, 3],\n",
       " [4, 5],\n",
       " [2, 3, 4, 5],\n",
       " [6, 7, 0, 1],\n",
       " [4, 5, 6, 7, 0, 1],\n",
       " [6, 7, 0, 1, 2, 3],\n",
       " [0, 1, 2],\n",
       " [5, 6],\n",
       " [4, 5, 6]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subsytems = [\n",
    "    2,\n",
    "    4,\n",
    "    6,\n",
    "    (2, 4),\n",
    "    (4, 6),\n",
    "    (2, 6),\n",
    "    (-2, 2),\n",
    "    (-4, 2),\n",
    "    (-2, 4),\n",
    "    3,\n",
    "    (5, 7),\n",
    "    (4, 7),\n",
    "]\n",
    "subsytems = [\n",
    "    list(range(i)) if isinstance(i, int) else [j % 8 for j in range(*i)]\n",
    "    for i in subsytems\n",
    "]\n",
    "# this is a list of subsystems that we want to measure\n",
    "subsytems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Name: bits_01\n",
      "| Name: bits_0123\n",
      "| Name: bits_012345\n",
      "| Name: bits_23\n",
      "| Name: bits_45\n",
      "| Name: bits_2345\n",
      "| Name: bits_6701\n",
      "| Name: bits_456701\n",
      "| Name: bits_670123\n",
      "| Name: bits_012\n",
      "| Name: bits_56\n",
      "| Name: bits_456\n"
     ]
    }
   ],
   "source": [
    "for qs in subsytems:\n",
    "    name = \"bits_\" + \"\".join([str(qi) for qi in qs])\n",
    "    print(\"| Name:\", name)\n",
    "    \n",
    "    # please decomment this cell to run it.\n",
    "    \n",
    "    # experiment_executor_02.multiAnalysis(\n",
    "    #     summoner_id=hash_id,\n",
    "    #     selected_qubits=qs,\n",
    "    #     analysis_name=name,\n",
    "    #     no_serialize=True,\n",
    "    # )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Export and Compress\n",
    "\n",
    "In this section, we will show how to use `multiWrite` to export the results of multiJob to a folder or export as a tar.xz file when `compress=True`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# please decomment this cell to run it.\n",
    "\n",
    "# experiment_executor_02.multiWrite(\n",
    "#     save_location=Path('./'),\n",
    "#     summoner_id=hash_id,\n",
    "#     compress=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Reading and Writing Data\n",
    "\n",
    "In this section, we will show how to use `multiRead` to load the results of multiJob.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Retrieve example.multiOutput.qurry.001...\n",
      "| at: example.multiOutput.qurry.001\n",
      "| Found the tarfile 'example.multiOutput.qurry.001.qurry.tar.xz' in '.', decompressing is available.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "786d3729eec14e3683c0aa64f8d0b3c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "| 0/10   0%|          | - 10 experiments found, loading by 4 workers. - 00:00 < ?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hashID = experiment_executor_02.multiRead(\n",
    "    save_location=Path('./'),\n",
    "    summoner_name='example.multiOutput.qurry.001',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Post-Process Availablities and Version Info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Qurry version: 0.10.1.dev2\n",
      " | Qurry version: 0.10.1.dev2\n",
      "--------------------------------------------------------\n",
      " ### Qurry Post-Processing\n",
      "   - Backend Availability ................... Python Cython Rust  \n",
      " - randomized_measure\n",
      "   - entangled_entropy.entropy_core_2 ....... Yes    Depr.  Yes   \n",
      "   - entangle_entropy.purity_cell_2 ......... Yes    Depr.  Yes   \n",
      "   - entangled_entropy_v1.entropy_core ...... Yes    Depr.  Yes   \n",
      "   - entangle_entropy_v1.purity_cell ........ Yes    Depr.  Yes   \n",
      "   - wavefunction_overlap.echo_core_2 ....... Yes    Depr.  Yes   \n",
      "   - wavefunction_overlap.echo_cell_2 ....... Yes    Depr.  Yes   \n",
      "   - wavefunction_overlap_v1.echo_core ...... Yes    Depr.  Yes   \n",
      "   - wavefunction_overlap_v1.echo_cell ...... Yes    Depr.  Yes   \n",
      " - hadamard_test\n",
      "   - purity_echo_core ....................... Yes    No     Yes   \n",
      " - magnet_square\n",
      "   - magnsq_core ............................ Yes    No     No    \n",
      " - utils\n",
      "   - randomized ............................. Yes    Depr.  Yes   \n",
      "   - construct .............................. Yes    No     Yes   \n",
      "   - dummy .................................. Yes    No     Yes   \n",
      "   - test ................................... Yes    No     Yes   \n",
      "--------------------------------------------------------\n",
      "   + Yes ...... Working normally.\n",
      "   + Error .... Exception occurred.\n",
      "   + No ....... Not supported.\n",
      "   + Depr. .... Deprecated.\n",
      "--------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from qurry import __version__\n",
    "from qurry.process import AVAIBILITY_STATESHEET\n",
    "print(\"| Qurry version:\", __version__)\n",
    "print(AVAIBILITY_STATESHEET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quantumsphere12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
